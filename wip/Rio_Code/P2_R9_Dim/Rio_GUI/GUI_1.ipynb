{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook for a general script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process:\n",
    "# 1. get input file, \n",
    "# 2. run the model\n",
    "# 3. post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# magic lines that avoid re-start \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import csv, random, os\n",
    "import pybamm as pb;import pandas as pd;import numpy as np;\n",
    "import os, json,openpyxl,traceback,multiprocessing,scipy.optimize\n",
    "import matplotlib.pyplot as plt;\n",
    "import imageio,timeit,random,time, signal\n",
    "from scipy.io import savemat,loadmat;\n",
    "from pybamm import constants,exp;import matplotlib as mpl; \n",
    "fs=17; \n",
    "font = {'family' : 'DejaVu Sans','size'   : fs}\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "On_HPC = False\n",
    "if On_HPC:                          # Run on HPC\n",
    "    Path_NiallDMA = \"InputData/\" \n",
    "    BasicPath=os.getcwd() \n",
    "    #Para_file = Path_NiallDMA +  para_csv\n",
    "else:\n",
    "    import sys  \n",
    "    str_path_0 = os.path.abspath(os.path.join(pb.__path__[0],'..'))\n",
    "    str_path_1 = os.path.abspath(\n",
    "        os.path.join(str_path_0,\"wip/Rio_Code/Fun_P2_s\"))\n",
    "    sys.path.append(str_path_1) \n",
    "    Path_NiallDMA = os.path.expanduser(\n",
    "        \"~/EnvPBGEM_Linux/SimSave/InputData/\") # for Linux\n",
    "    BasicPath =  os.path.expanduser(\n",
    "        \"~/EnvPBGEM_Linux/SimSave/P2_R9_Dim\")\n",
    "    #Para_file = BasicPath+'/Get_Random_sets/'+para_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get input file or just input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions, will put into the .py file later\n",
    "def save_rows_to_csv(file_path, rows, header):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)  # Write parameter names as the header row\n",
    "        writer.writerows(rows)\n",
    "def generate_combinations(Bounds, Num_tot):\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    for bound in Bounds:\n",
    "        lower_bounds.append(bound[0])\n",
    "        upper_bounds.append(bound[1])\n",
    "    combinations = []\n",
    "    for _ in range(Num_tot):\n",
    "        combination = []\n",
    "        for lower, upper in zip(lower_bounds, upper_bounds):\n",
    "            value = random.uniform(lower, upper)\n",
    "            combination.append(value)\n",
    "        combinations.append(combination)\n",
    "    return combinations\n",
    "\n",
    "def save_combinations_to_csv(combinations, parameter_names, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(parameter_names)  # Write parameter names as the first row\n",
    "        for combination in combinations:\n",
    "            writer.writerow(combination)\n",
    "# Pack input needs to be a list\n",
    "def Get_Scan_files(\n",
    "        BasicPath,Target_name,model_options,\n",
    "        parameter_names,para_short_name,\n",
    "        Pack,\n",
    "        rows_per_file,Bundle):\n",
    "    \n",
    "    import itertools\n",
    "    para_dict_Same = {\n",
    "        \"Cycles within RPT\":1,\n",
    "        \"RPT temperature\":25,\n",
    "        \"Mesh list\":[5,5,5,60,20],  \n",
    "        \"Para_Set\": \"OKane2023\",\n",
    "        \"Model option\":model_options,\n",
    "        \"Current solvent concentration in the reservoir [mol.m-3]\":4541.0,\n",
    "        \"Current electrolyte concentration in the reservoir [mol.m-3]\":1000,\n",
    "        \"Ratio of Li-ion concentration change in \" \n",
    "        \"electrolyte consider solvent consumption\":1.0,\n",
    "        'EC initial concentration in electrolyte [mol.m-3]':4541.0,\n",
    "        'Typical EC concentration in electrolyte [mol.m-3]':4541.0, \n",
    "        \"Negative electrode number of cracks per unit area [m-2]\": 3.18e15,\n",
    "        \"Initial inner SEI thickness [m]\": 1.23625e-08,\n",
    "        \"Initial outer SEI thickness [m]\": 1.23625e-08,\n",
    "        \"Negative electrode porosity\": 0.222393,\n",
    "        }\n",
    "    unchange_key2 = list(para_dict_Same.keys())\n",
    "    unchange_val2 = list(para_dict_Same.values())\n",
    "    short_pack = [lst for lst in Pack if len(lst) > 1]\n",
    "    selected_indices = [i for i, lst in enumerate(Pack) if len(lst) > 1]\n",
    "    shortList_para_short_name = [para_short_name[i] for i in selected_indices]\n",
    "    shortList_para_short_name.insert(0,\"No\")\n",
    "    really_change_val =  [\n",
    "        list(comb) for comb in itertools.product(*short_pack)]\n",
    "\n",
    "    change_val =  [\n",
    "        list(comb) for comb in itertools.product(*Pack)]\n",
    "    combinations = [[i+1,*elem, *unchange_val2] for i,elem in enumerate(change_val)]\n",
    "    comb_short   = [[i+1,*elem] for i,elem in enumerate(really_change_val)]\n",
    "    parameter_names = [*parameter_names,*unchange_key2]\n",
    "    print(\"Total cases number is\",len(combinations))\n",
    "    if Bundle:\n",
    "        # Specify the total number of cases\n",
    "        total_cases = len(combinations)\n",
    "        # Specify the number of rows per CSV file, rows_per_file\n",
    "        # Calculate the number of files needed\n",
    "        num_files = (total_cases - 1) // rows_per_file + 1\n",
    "        # Create the target folder\n",
    "        folder_path = os.path.join(BasicPath, \"Get_Random_sets\", Target_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        # Write data to each CSV file\n",
    "        for i in range(num_files):\n",
    "            file_name = f\"Bundle_{i+1}.csv\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            start_row = i * rows_per_file\n",
    "            end_row = min(start_row + rows_per_file, total_cases)\n",
    "            rows = combinations[start_row:end_row]\n",
    "            save_rows_to_csv(file_path, rows, parameter_names)\n",
    "        filename = BasicPath+f\"/Get_Random_sets/{Target_name}/\"+f'{Target_name}.csv'\n",
    "        filename_short = BasicPath+f\"/Get_Random_sets/{Target_name}/\"+f'{Target_name}_s.csv'\n",
    "        save_combinations_to_csv(combinations, parameter_names, filename)\n",
    "        save_combinations_to_csv(comb_short, shortList_para_short_name, filename_short)\n",
    "        print(f\"Combinations saved to '{Target_name}.csv' file.\") \n",
    "        print(f\"CSV files created in folder '{Target_name}'.\")\n",
    "    else:\n",
    "        filename = BasicPath+\"/Get_Random_sets/\"+f'{Target_name}.csv'\n",
    "        save_combinations_to_csv(combinations, parameter_names, filename)\n",
    "        print(f\"Combinations saved to '{Target_name}.csv' file.\") \n",
    "    return len(combinations)\n",
    "# pack input can not either be a list or a tuple\n",
    "def get_list_from_tuple(d, num):\n",
    "    if d[1] > d[0]:\n",
    "        if d[1] > 100 * d[0]:\n",
    "            result_list = (np.exp(np.linspace(np.log(d[0]), np.log(d[1]), num=num))).tolist()\n",
    "        else:\n",
    "            result_list = (np.linspace(d[0], d[1], num=num)).tolist()\n",
    "    else:\n",
    "        result_list = []\n",
    "    return result_list\n",
    "def Get_Scan_Orth_Latin(\n",
    "        BasicPath,Target_name,model_options,\n",
    "        parameter_names,para_short_name,\n",
    "        Pack, num,\n",
    "        rows_per_file,Bundle):\n",
    "    \n",
    "    import itertools; from pyDOE import lhs\n",
    "    para_dict_Same = {\n",
    "        \"Cycles within RPT\":1,\n",
    "        \"RPT temperature\":25,\n",
    "        \"Mesh list\":[5,5,5,60,20],  \n",
    "        \"Para_Set\": \"OKane2023\",\n",
    "        \"Model option\":model_options,\n",
    "        \"Current solvent concentration in the reservoir [mol.m-3]\":4541.0,\n",
    "        \"Current electrolyte concentration in the reservoir [mol.m-3]\":1000,\n",
    "        \"Ratio of Li-ion concentration change in \" \n",
    "        \"electrolyte consider solvent consumption\":1.0,\n",
    "        'EC initial concentration in electrolyte [mol.m-3]':4541.0,\n",
    "        'Typical EC concentration in electrolyte [mol.m-3]':4541.0, \n",
    "        \"Negative electrode number of cracks per unit area [m-2]\": 3.18e15,\n",
    "        \"Initial inner SEI thickness [m]\": 1.23625e-08,\n",
    "        \"Initial outer SEI thickness [m]\": 1.23625e-08,\n",
    "        \"Negative electrode porosity\": 0.222393,\n",
    "        }\n",
    "    unchange_key2 = list(para_dict_Same.keys())\n",
    "    unchange_val2 = list(para_dict_Same.values())\n",
    "    \n",
    "    Pack_tuple = []; Pack_tuple_index = []\n",
    "    Pack_list = [];  Pack_list_index  = []\n",
    "    for i,item in enumerate(Pack):\n",
    "        if isinstance(item, tuple):\n",
    "            Pack_tuple.append(item)\n",
    "            Pack_tuple_index.append(i)\n",
    "        elif isinstance(item, list):\n",
    "            Pack_list.append(item)\n",
    "            Pack_list_index.append(i)\n",
    "    com_tuple = []; comb_tu_list =[]\n",
    "    if len(Pack_tuple) > 1:\n",
    "        for tuple_i in Pack_tuple:\n",
    "            com_tuple.append( get_list_from_tuple(tuple_i, num) )\n",
    "        # apply Latin Hypercube:\n",
    "        #print(com_tuple)\n",
    "        samples = lhs(len(com_tuple), samples=num)\n",
    "        for sample in samples:\n",
    "            combination = []\n",
    "            for i, candidate_list in enumerate(com_tuple):\n",
    "                index = int(sample[i] * num)\n",
    "                combination.append(candidate_list[index])\n",
    "            comb_tu_list.append(combination)\n",
    "    else:\n",
    "        print(\"error! Pack_tuple must has 2 elements\")\n",
    "    # apply product sampling:\n",
    "    comb_li_list = [list(comb) for comb in itertools.product(*Pack_list)]\n",
    "    #print(comb_tu_list)\n",
    "    #print(comb_li_list)\n",
    "    Big_Comb = []\n",
    "    for comb_tu in comb_tu_list:\n",
    "        for comb_li in comb_li_list:\n",
    "            big_comb = [0] * (len(comb_tu)+len(comb_li))\n",
    "            for comb_tu_i,index in zip(comb_tu,Pack_tuple_index):\n",
    "                big_comb[index] = comb_tu_i\n",
    "            for comb_li_i,index in zip(comb_li,Pack_list_index):\n",
    "                big_comb[index] = comb_li_i\n",
    "            Big_Comb.append(big_comb)\n",
    "    #print(Big_Comb)\n",
    "    Big_Comb\n",
    "    combinations = [[i+1,*elem, *unchange_val2] for i,elem in enumerate(Big_Comb)]\n",
    "\n",
    "    parameter_names = [*parameter_names,*unchange_key2]\n",
    "    print(\"Total cases number is\",len(combinations))\n",
    "    if Bundle:\n",
    "        # Specify the total number of cases\n",
    "        total_cases = len(combinations)\n",
    "        # Specify the number of rows per CSV file, rows_per_file\n",
    "        # Calculate the number of files needed\n",
    "        num_files = (total_cases - 1) // rows_per_file + 1\n",
    "        # Create the target folder\n",
    "        folder_path = os.path.join(BasicPath, \"Get_Random_sets\", Target_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        # Write data to each CSV file\n",
    "        for i in range(num_files):\n",
    "            file_name = f\"Bundle_{i+1}.csv\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            start_row = i * rows_per_file\n",
    "            end_row = min(start_row + rows_per_file, total_cases)\n",
    "            rows = combinations[start_row:end_row]\n",
    "            save_rows_to_csv(file_path, rows, parameter_names)\n",
    "        filename = BasicPath+f\"/Get_Random_sets/{Target_name}/\"+f'{Target_name}.csv'\n",
    "        filename_short = BasicPath+f\"/Get_Random_sets/{Target_name}/\"+f'{Target_name}_s.csv'\n",
    "        save_combinations_to_csv(combinations, parameter_names, filename)\n",
    "        # save_combinations_to_csv(comb_short, shortList_para_short_name, filename_short)\n",
    "        print(f\"Combinations saved to '{Target_name}.csv' file.\") \n",
    "        print(f\"CSV files created in folder '{Target_name}'.\")\n",
    "    else:\n",
    "        filename = BasicPath+\"/Get_Random_sets/\"+f'{Target_name}.csv'\n",
    "        save_combinations_to_csv(combinations, parameter_names, filename)\n",
    "        print(f\"Combinations saved to '{Target_name}.csv' file.\") \n",
    "    return len(combinations)\n",
    "\n",
    "def Get_Scan_General(\n",
    "        BasicPath,Target_name,Para_dict, \n",
    "        num,rows_per_file,Bundle=True):\n",
    "        \n",
    "    ParaDict_unchange ={}; ParaDict_change_List = {}; ParaDict_change_Tuple = {}\n",
    "    for key, value in Para_dict.items():\n",
    "        # depending on what values is:\n",
    "        # it is a list, then it is changing\n",
    "        if isinstance(value,list):\n",
    "            if len(value) >1:\n",
    "                #print(value)\n",
    "                ParaDict_change_List[key] = value\n",
    "            else:\n",
    "                ParaDict_unchange[key] = value[0]\n",
    "        # it is a list, so it also changes\n",
    "        elif isinstance(value,tuple):\n",
    "            #print(value)\n",
    "            # create a list based on the tuple:\n",
    "            ParaDict_change_Tuple[key] = get_list_from_tuple(value, num)\n",
    "        else:\n",
    "            ParaDict_unchange[key] = value\n",
    "    if len(ParaDict_change_List) > 1:\n",
    "        comb_li_list = [list(comb) for comb in itertools.product(*ParaDict_change_List.values())]\n",
    "    elif len(ParaDict_change_List) == 0:\n",
    "        comb_li_list = []\n",
    "    else:\n",
    "        comb_li_list = list(ParaDict_change_List.values())\n",
    "        #print(comb_li_list)\n",
    "        comb_li_list = comb_li_list [0]\n",
    "    #comb_li_list\n",
    "    import itertools; from pyDOE import lhs\n",
    "    comb_tu_list =[]\n",
    "    if len(ParaDict_change_Tuple) > 1:\n",
    "        samples = lhs(len(ParaDict_change_Tuple), samples=num)\n",
    "        for sample in samples:\n",
    "            combination = []\n",
    "            for i, candidate_list in enumerate(ParaDict_change_Tuple.values()):\n",
    "                index = int(sample[i] * num)\n",
    "                combination.append(candidate_list[index])\n",
    "            comb_tu_list.append(combination)\n",
    "    elif len(ParaDict_change_Tuple) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        comb_tu_list = list(ParaDict_change_Tuple.values())\n",
    "        comb_tu_list = comb_tu_list[0]\n",
    "    #comb_tu_list\n",
    "    Big_Comb = []\n",
    "    for comb_li in comb_li_list:\n",
    "        for comb_tu in comb_tu_list:\n",
    "            if isinstance(comb_tu,list):\n",
    "                if isinstance(comb_li,list) :\n",
    "                    Big_Comb.append([*comb_li,*comb_tu,])\n",
    "                else:\n",
    "                    Big_Comb.append([comb_li,*comb_tu,]) \n",
    "            else:\n",
    "                if isinstance(comb_li,list):\n",
    "                    Big_Comb.append([*comb_li,comb_tu,])\n",
    "                else:\n",
    "                    Big_Comb.append([comb_li,comb_tu,])  \n",
    "    if len(Big_Comb) > 1:\n",
    "        print(f\"Total scan number is: {len(Big_Comb)}\")\n",
    "        comb_short = [[i+1,*elem, ] for i,elem in enumerate(Big_Comb)]\n",
    "        short_name_List =  [\n",
    "            \"Scan No\",\n",
    "            *list(ParaDict_change_List.keys()),\n",
    "            *list(ParaDict_change_Tuple.keys()),]\n",
    "        combinations = [[i+1,*elem, *ParaDict_unchange.values()] for i,elem in enumerate(Big_Comb)]\n",
    "        parameter_names = [\n",
    "            \"Scan No\",\n",
    "            *list(ParaDict_change_List.keys()),\n",
    "            *list(ParaDict_change_Tuple.keys()),\n",
    "            *list(ParaDict_unchange.keys())]\n",
    "    else:\n",
    "        print(f\"Total scan number is: 1\")\n",
    "        combinations = [[1, *ParaDict_unchange.values()]]\n",
    "        parameter_names = [\n",
    "            \"Scan No\",\n",
    "            *list(ParaDict_unchange.keys())]\n",
    "\n",
    "    if Bundle:\n",
    "        # Specify the total number of cases\n",
    "        total_cases = len(combinations)\n",
    "        # Specify the number of rows per CSV file, rows_per_file\n",
    "        # Calculate the number of files needed\n",
    "        num_files = (total_cases - 1) // rows_per_file + 1\n",
    "        # Create the target folder\n",
    "        folder_path = os.path.join(BasicPath, \"Get_Random_sets\", Target_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        # Write data to each CSV file\n",
    "        for i in range(num_files):\n",
    "            file_name = f\"Bundle_{i+1}.csv\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            start_row = i * rows_per_file\n",
    "            end_row = min(start_row + rows_per_file, total_cases)\n",
    "            rows = combinations[start_row:end_row]\n",
    "            save_rows_to_csv(file_path, rows, parameter_names)\n",
    "        filename = BasicPath+f\"/Get_Random_sets/{Target_name}/\"+f'{Target_name}.csv'\n",
    "        filename_short = BasicPath+f\"/Get_Random_sets/{Target_name}/\"+f'{Target_name}_s.csv'\n",
    "        save_combinations_to_csv(combinations, parameter_names, filename)\n",
    "        if len(Big_Comb) > 1:\n",
    "            save_combinations_to_csv(comb_short, short_name_List, filename_short)\n",
    "        print(f\"Combinations saved to '{Target_name}.csv' file.\") \n",
    "        print(f\"CSV files created in folder '{Target_name}'.\")\n",
    "    else:\n",
    "        filename = BasicPath+\"/Get_Random_sets/\"+f'{Target_name}.csv'\n",
    "        filename_short = BasicPath+f\"/Get_Random_sets/\"+f'{Target_name}_s.csv'\n",
    "        save_combinations_to_csv(combinations, parameter_names, filename)\n",
    "        if len(Big_Comb) > 1:\n",
    "            save_combinations_to_csv(comb_short, short_name_List, filename_short)\n",
    "        print(f\"Combinations saved to '{Target_name}.csv' file.\") \n",
    "    return parameter_names,combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_SEI = {\n",
    "    \"SEI\": \"interstitial-diffusion limited\",\n",
    "    \"SEI on cracks\": \"true\",\n",
    "    \n",
    "    \"lithium plating\": \"none\",\n",
    "    \"lithium plating porosity change\":\"false\",\n",
    "    \"particle mechanics\": \"constant cracks\",\n",
    "    \"loss of active material\": \"none\",\n",
    "\n",
    "    \"contact resistance\": \"true\",\n",
    "    \"open-circuit potential\": \"current sigmoid\",\n",
    "    \"SEI film resistance\": \"distributed\", \n",
    "    \"SEI porosity change\": \"true\",\n",
    "    \"thermal\": \"lumped\",\n",
    "}\n",
    "BasicPath =  os.path.expanduser(\n",
    "   \"~/EnvPBGEM_Linux/SimSave/P2_R9_Dim\")\n",
    "Target  = f'/Get_Random_sets/'\n",
    "if not os.path.exists(BasicPath + Target):\n",
    "   os.mkdir(BasicPath + Target)\n",
    "\n",
    "num = 10; rows_per_file = 3\n",
    "Para_dict = {\n",
    "    ###################### setting\n",
    "    # change: \n",
    "    #\"Scan No\",   # by default, \n",
    "    \"Exp No\":[2],   # 2,3,5\n",
    "    \"Ageing temperature\":10.0, # 10,25,40\n",
    "\n",
    "    # unchange\n",
    "    \"Cycles within RPT\":1,\n",
    "    \"RPT temperature\":25,\n",
    "    \"Mesh list\":\"[5,5,5,60,20]\",  \n",
    "    \"Para_Set\": \"OKane2023\",\n",
    "    \"Model option\":options_SEI,\n",
    "    \"Current solvent concentration in the reservoir [mol.m-3]\":4541.0,\n",
    "    \"Current electrolyte concentration in the reservoir [mol.m-3]\":1000,\n",
    "    \"Ratio of Li-ion concentration change in \" \n",
    "    \"electrolyte consider solvent consumption\":1.0,\n",
    "    'EC initial concentration in electrolyte [mol.m-3]':4541.0,\n",
    "    'Typical EC concentration in electrolyte [mol.m-3]':4541.0, \n",
    "\n",
    "    ###################### parameter that already there\n",
    "    # change:\n",
    "\n",
    "\n",
    "    # unchange:\n",
    "    'Inner SEI lithium interstitial diffusivity [m2.s-1]':[2.68e-18],#1e-19~5e-18\n",
    "    'Dead lithium decay constant [s-1]': 1e-6,\n",
    "    'Lithium plating kinetic rate constant [m.s-1]':1e-15,\n",
    "    'Negative electrode LAM constant proportional term [s-1]':[3e-7,],\n",
    "    'Positive electrode LAM constant proportional term [s-1]':[3e-7,],\n",
    "    'Negative electrode cracking rate':[1e-20,],\n",
    "    'Outer SEI partial molar volume [m3.mol-1]':[4e-5],\n",
    "    \"SEI growth activation energy [J.mol-1]\":[1e4,], # 1e4~3.8e4\n",
    "    \"Negative cracking growth activation energy [J.mol-1]\":[0.0,],#0\n",
    "    \"Negative electrode diffusivity activation energy [J.mol-1]\":[1.7e4,],#1.7e4\n",
    "    \"Positive electrode diffusivity activation energy [J.mol-1]\":[1.2e4,],#1.2e4\n",
    "    \"Contact resistance [Ohm]\":[0.010,],#0.010\n",
    "    'Total heat transfer coefficient [W.m-2.K-1]': [20,],#20\n",
    "    'Initial electrolyte excessive amount ratio':[1.0,], # 1.0 or 0.99\n",
    "    \"Ratio of lithium moles to SEI moles\":[2.0,], # 2.0\n",
    "    \"Negative electrode number of cracks per unit area [m-2]\": 3.18e15,\n",
    "    \"Initial inner SEI thickness [m]\": 1.23625e-08,\n",
    "    \"Initial outer SEI thickness [m]\": 1.23625e-08,\n",
    "    \"Negative electrode porosity\": 0.222393,\n",
    "}\n",
    "\n",
    "Target_name = \"Test_2\"\n",
    "parameter_names,combinations = Get_Scan_General(\n",
    "    BasicPath,Target_name,Para_dict, \n",
    "    num,rows_per_file,Bundle=False)\n",
    "\n",
    "para_one = {}\n",
    "for para,combination_i in zip(parameter_names,combinations[0]):\n",
    "   para_one[para]  = combination_i\n",
    "para_one['Mesh list'] = json.loads(para_one['Mesh list'])\n",
    "para_one['Mesh list']\n",
    "para_one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvPBGEM_Linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
